return {
  {
    "jackMort/ChatGPT.nvim",
    event = "VeryLazy",
    dependencies = {
      "MunifTanjim/nui.nvim",
      "nvim-lua/plenary.nvim",
      "nvim-telescope/telescope.nvim",
    },
    config = function()
      -- ‚úÖ Models with cost per 1M tokens
      local models = {
        four_o_mini = { name = "gpt-4o-mini", input_cost = 0.15, output_cost = 0.60 },
        o3_mini = { name = "gpt-4o3-mini", input_cost = 1.10, output_cost = 4.40 },
      }

      -- ‚úÖ Default: GPT-4o Mini (cheapest)
      vim.g.current_model = models.four_o_mini

      -- ‚úÖ Function to calculate & display cost
      local function calculate_cost(prompt_tokens, completion_tokens)
        local model = vim.g.current_model
        local input_cost = (prompt_tokens / 1000000) * model.input_cost
        local output_cost = (completion_tokens / 1000000) * model.output_cost
        local total_cost = input_cost + output_cost
        print(string.format("üí∞ Cost: $%.6f (Tokens: %d in, %d out)", total_cost, prompt_tokens, completion_tokens))
      end

      -- ‚úÖ Function to switch models
      local function set_model(m)
        vim.g.current_model = models[m]
        require("chatgpt").setup({
          api_key_cmd = "echo $OPENAI_API_KEY",
          openai_params = {
            model = vim.g.current_model.name,
          },
          popup_input = {
            prompt = "üîç Enter your request: ",
            submit = "<C-Enter>",
          },
          popup_window = {
            border = "rounded",
            width = 80,
            height = 20,
          },
        })
        print("üîÑ Switched to Model: " .. vim.g.current_model.name)
      end

      -- ‚úÖ Setup ChatGPT.nvim with cost tracking
      require("chatgpt").setup({
        api_key_cmd = "echo $OPENAI_API_KEY",
        openai_params = {
          model = vim.g.current_model.name,
        },
        popup_input = {
          prompt = "üîç Enter your request: ",
          submit = "<C-Enter>",
        },
        popup_window = {
          border = "rounded",
          width = 80,
          height = 20,
        },
        edit_with_instructions = {
          diff = false,
          keymaps = {
            accept = "<C-y>",
            dismiss = "<C-c>",
          },
        },
        on_response = function(response)
          if response.usage then
            calculate_cost(response.usage.prompt_tokens, response.usage.completion_tokens)
          else
            print("‚ö†Ô∏è No token usage data received.")
          end
        end,
      })

      -- ‚úÖ Keybindings for AI-assisted coding & model switching
      local function set_keymaps()
        vim.keymap.set("i", "<C-Enter>", "<Cmd>ChatGPTCompleteCode<CR>", { noremap = true, silent = true })
        vim.keymap.set("n", "<leader>cg", ":ChatGPT<CR>", { noremap = true, silent = true })
        vim.keymap.set("v", "<leader>ce", ":ChatGPTEditWithInstruction<CR>", { noremap = true, silent = true })
        vim.keymap.set("n", "<leader>cy", ":ChatGPTYankLast<CR>", { noremap = true, silent = true })
        vim.keymap.set("n", "<leader>gm", function()
          set_model("four_o_mini")
        end, { noremap = true, silent = true }) -- Switch to GPT-4o Mini
        vim.keymap.set("n", "<leader>go", function()
          set_model("o3_mini")
        end, { noremap = true, silent = true }) -- Switch to GPT-4o3 Mini
      end

      set_keymaps()
      print("üî• GPT-4o Mini is the default model. Use `<leader>go>` for GPT-4o3 Mini.")
    end,
  },
}
